{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8569a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import numpy as np \n",
    "import random \n",
    "import json \n",
    "  \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1d2c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the data: dict_keys(['intents'])\n",
      "Type of 'intents': <class 'list'>\n",
      "Number of intents: 22\n",
      "Keys in the first intent: dict_keys(['intent', 'text', 'responses', 'extension', 'context', 'entityType', 'entities'])\n",
      "Last intent data: {'intent': 'SelfAware', 'text': ['Can you prove you are self-aware', 'Can you prove you are self aware', 'Can you prove you have a conscious', 'Can you prove you are self-aware please', 'Can you prove you are self aware please', 'Can you prove you have a conscious please', 'prove you have a conscious'], 'responses': ['That is an interesting question, can you prove that you are?', 'That is an difficult question, can you prove that you are?', 'That depends, can you prove that you are?'], 'extension': {'function': '', 'entities': False, 'responses': []}, 'context': {'in': '', 'out': '', 'clear': False}, 'entityType': 'NA', 'entities': []}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('Intent.json', 'r') as f: \n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Keys in the data:\", data.keys())\n",
    "print(\"Type of 'intents':\", type(data['intents']))\n",
    "print(\"Number of intents:\", len(data['intents']))\n",
    "print(\"Keys in the first intent:\", data['intents'][0].keys())\n",
    "print(\"Last intent data:\", data['intents'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0335a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(line): \n",
    "\tcleaned_line = '' \n",
    "\tfor char in line: \n",
    "\t\tif char.isalpha(): \n",
    "\t\t\tcleaned_line += char \n",
    "\t\telse: \n",
    "\t\t\tcleaned_line += ' '\n",
    "\tcleaned_line = ' '.join(cleaned_line.split()) \n",
    "\treturn cleaned_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0250ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = []\n",
    "unique_intents = []\n",
    "text_input = []\n",
    "response_for_intent = {}\n",
    "\n",
    "for intent in data['intents']:\n",
    "    unique_intents.append(intent['intent'])\n",
    "\n",
    "    for text in intent['text']:\n",
    "        text_input.append(clean(text))\n",
    "        intents.append(intent['intent'])\n",
    "    \n",
    "    response_for_intent[intent['intent']] = intent['responses']\n",
    "\n",
    "unique_intents = list(set(unique_intents))  # Remove duplicates from unique_intents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003fb1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent : Greeting\n",
      "Number of Intent: 143\n",
      "Sample Input: Hi\n",
      "Length of text_input: 143\n",
      "Sample Response:  ['Hi human, please tell me your GeniSys user', 'Hello human, please tell me your GeniSys user', 'Hola human, please tell me your GeniSys user']\n"
     ]
    }
   ],
   "source": [
    "print(\"Intent :\",intents[0]) \n",
    "print(\"Number of Intent:\",len(intents)) \n",
    "print(\"Sample Input:\", text_input[0]) \n",
    "print('Length of text_input:',len(text_input)) \n",
    "print(\"Sample Response: \", response_for_intent[intents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73b4af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Sequence: (143, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0, 52],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 52, 53],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 68],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 39],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 39, 53]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='',oov_token='<unk>') \n",
    "tokenizer.fit_on_texts(text_input) \n",
    "sequences = tokenizer.texts_to_sequences(text_input) \n",
    "padded_sequences = pad_sequences(sequences, padding='pre') \n",
    "print('Shape of Input Sequence:',padded_sequences.shape) \n",
    "padded_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96bc268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Intents: 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'CourtesyGoodBye',\n",
       " 1: 'UnderstandQuery',\n",
       " 2: 'PodBayDoorResponse',\n",
       " 3: 'SelfAware',\n",
       " 4: 'NameQuery',\n",
       " 5: 'Greeting',\n",
       " 6: 'Jokes',\n",
       " 7: 'NotTalking2U',\n",
       " 8: 'GreetingResponse',\n",
       " 9: 'Gossip',\n",
       " 10: 'PodBayDoor',\n",
       " 11: 'Thanks',\n",
       " 12: 'TimeQuery',\n",
       " 13: 'GoodBye',\n",
       " 14: 'Shutup',\n",
       " 15: 'RealNameQuery',\n",
       " 16: 'Clever',\n",
       " 17: 'CourtesyGreetingResponse',\n",
       " 18: 'CurrentHumanQuery',\n",
       " 19: 'WhoAmI',\n",
       " 20: 'Swearing',\n",
       " 21: 'CourtesyGreeting'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_to_index = {}\n",
    "categorical_target = []\n",
    "\n",
    "for index, intent in enumerate(set(intents)):\n",
    "    intent_to_index[intent] = index\n",
    "\n",
    "categorical_target = [intent_to_index[intent] for intent in intents]\n",
    "\n",
    "num_classes = len(intent_to_index)\n",
    "print('Number of Intents:', num_classes)\n",
    "\n",
    "index_to_intent = {index: intent for intent, index in intent_to_index.items()}\n",
    "index_to_intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "748ea4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of categorical vector: (143, 22)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "categorical_vec = tf.keras.utils.to_categorical(categorical_target, num_classes=num_classes)\n",
    "print('Shape of categorical vector:', categorical_vec.shape)\n",
    "print(categorical_vec[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75d3bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dimension :22,\n",
      "Output Dimension :22\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "embed_dim=300\n",
    "lstm_num=50\n",
    "output_dim=categorical_vec.shape[1] \n",
    "input_dim=len(unique_intents) \n",
    "print(\"Input Dimension :{},\\nOutput Dimension :{}\".format(input_dim,output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75498993",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the parameters\n",
    "embed_dim = 300\n",
    "lstm_num = 50\n",
    "output_dim = 22\n",
    "\n",
    "# Assuming tokenizer.word_index is already defined\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, dropout=0.1, return_sequences=False)),\n",
    "    tf.keras.layers.Dense(lstm_num, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(output_dim, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f648fb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 243ms/step - accuracy: 0.0572 - loss: 3.0913 - val_accuracy: 0.0345 - val_loss: 3.0992\n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0697 - loss: 3.0692 - val_accuracy: 0.0345 - val_loss: 3.0992\n",
      "Epoch 3/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1185 - loss: 3.0554 - val_accuracy: 0.0345 - val_loss: 3.0929\n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1904 - loss: 3.0155 - val_accuracy: 0.0690 - val_loss: 3.0897\n",
      "Epoch 5/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1642 - loss: 3.0371 - val_accuracy: 0.1034 - val_loss: 3.0767\n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1800 - loss: 2.9843 - val_accuracy: 0.1034 - val_loss: 3.0612\n",
      "Epoch 7/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3127 - loss: 2.9246 - val_accuracy: 0.1034 - val_loss: 3.0511\n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2644 - loss: 2.8925 - val_accuracy: 0.1034 - val_loss: 3.0378\n",
      "Epoch 9/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2970 - loss: 2.8076 - val_accuracy: 0.1034 - val_loss: 3.0180\n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3144 - loss: 2.7706 - val_accuracy: 0.1034 - val_loss: 2.9822\n",
      "Epoch 11/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2907 - loss: 2.6027 - val_accuracy: 0.1379 - val_loss: 2.9311\n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3228 - loss: 2.5880 - val_accuracy: 0.1379 - val_loss: 2.8546\n",
      "Epoch 13/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3549 - loss: 2.3395 - val_accuracy: 0.2414 - val_loss: 2.7713\n",
      "Epoch 14/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3682 - loss: 2.3195 - val_accuracy: 0.3448 - val_loss: 2.6595\n",
      "Epoch 15/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4774 - loss: 2.0995 - val_accuracy: 0.4138 - val_loss: 2.5305\n",
      "Epoch 16/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4120 - loss: 1.9707 - val_accuracy: 0.4138 - val_loss: 2.4174\n",
      "Epoch 17/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5160 - loss: 1.8646 - val_accuracy: 0.4483 - val_loss: 2.2953\n",
      "Epoch 18/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5090 - loss: 1.7065 - val_accuracy: 0.4483 - val_loss: 2.1739\n",
      "Epoch 19/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5871 - loss: 1.4985 - val_accuracy: 0.5172 - val_loss: 2.0122\n",
      "Epoch 20/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6743 - loss: 1.2812 - val_accuracy: 0.4828 - val_loss: 1.9694\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "with open('Intent.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Function to clean the text data\n",
    "def clean(line):\n",
    "    cleaned_line = ''\n",
    "    for char in line:\n",
    "        if char.isalpha():\n",
    "            cleaned_line += char\n",
    "        else:\n",
    "            cleaned_line += ' '\n",
    "    cleaned_line = ' '.join(cleaned_line.split())\n",
    "    return cleaned_line\n",
    "\n",
    "# Prepare the data\n",
    "intents = []\n",
    "unique_intents = []\n",
    "text_input = []\n",
    "response_for_intent = {}\n",
    "\n",
    "for intent in data['intents']:\n",
    "    unique_intents.append(intent['intent'])\n",
    "    for text in intent['text']:\n",
    "        text_input.append(clean(text))\n",
    "        intents.append(intent['intent'])\n",
    "    response_for_intent[intent['intent']] = intent['responses']\n",
    "\n",
    "unique_intents = list(set(unique_intents))  # Remove duplicates from unique_intents\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(filters='', oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(text_input)\n",
    "sequences = tokenizer.texts_to_sequences(text_input)\n",
    "padded_sequences = pad_sequences(sequences, padding='pre')\n",
    "\n",
    "# Prepare the target data\n",
    "intent_to_index = {}\n",
    "for index, intent in enumerate(set(intents)):\n",
    "    intent_to_index[intent] = index\n",
    "\n",
    "categorical_target = [intent_to_index[intent] for intent in intents]\n",
    "num_classes = len(intent_to_index)\n",
    "categorical_vec = tf.keras.utils.to_categorical(categorical_target, num_classes=num_classes)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, categorical_vec, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model parameters\n",
    "embed_dim = 300\n",
    "lstm_num = 50\n",
    "output_dim = num_classes  # Use the number of classes for output_dim\n",
    "\n",
    "# Define the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, dropout=0.1, return_sequences=False)),\n",
    "    tf.keras.layers.Dense(lstm_num, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(output_dim, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,  # Adjust the number of epochs as needed\n",
    "    batch_size=32,  # Adjust the batch size as needed\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff060881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28b9fed8510>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sequences, categorical_vec, epochs=epochs, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e85c02cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782ms/step - accuracy: 0.8333 - loss: 0.4778\n"
     ]
    }
   ],
   "source": [
    "test_text_inputs = [\"Hello\",  \n",
    "                    \"my name is adam\",  \n",
    "                    \"how are you?\",  \n",
    "                    \"can you guess my name?\", \n",
    "                    \"Do you get me\",\"Adios\"] \n",
    "  \n",
    "test_intents = [\"Greeting\", \n",
    "                \"GreetingResponse\", \n",
    "                \"CourtesyGreeting\", \n",
    "                \"CurrentHumanQuery\", \n",
    "                \"UnderstandQuery\", \n",
    "                \"GoodBye\"] \n",
    "  \n",
    "test_sequences = tokenizer.texts_to_sequences(test_text_inputs) \n",
    "test_padded_sequences = pad_sequences(test_sequences,  padding='pre') \n",
    "test_labels = np.array([unique_intents.index(intent) for intent in test_intents]) \n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes) \n",
    "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b915ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(sentence): \n",
    "    sent_tokens = [] \n",
    "    # Split the input sentence into words \n",
    "    words = sentence.split() \n",
    "    # Convert words to their corresponding word indices \n",
    "    for word in words:                                            \n",
    "        if word in tokenizer.word_index: \n",
    "            sent_tokens.append(tokenizer.word_index[word]) \n",
    "        else: \n",
    "            # Handle unknown words \n",
    "            sent_tokens.append(tokenizer.word_index['<unk>']) \n",
    "    sent_tokens = tf.expand_dims(sent_tokens, 0) \n",
    "    #predict numerical category \n",
    "    pred = model(sent_tokens)     \n",
    "    #category to intent \n",
    "    pred_class = np.argmax(pred.numpy(), axis=1)                 \n",
    "    # random response to that intent \n",
    "    return random.choice( \n",
    "        response_for_intent[index_to_intent[pred_class[0]]]), index_to_intent[pred_class[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c207b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Enter 'quit' to break the loop.\n",
      "You: how are you\n",
      "Geek: Hello, I am good thank you, how are you? Please tell me your GeniSys user -- TYPE: CourtesyGreeting\n",
      "\n",
      "You: i study in college\n",
      "Geek: Let me see -- TYPE: WhoAmI\n",
      "\n",
      "You: who am i\n",
      "Geek: You are <HUMAN>! How can I help? -- TYPE: CurrentHumanQuery\n",
      "\n",
      "You: goof\n",
      "Geek: Jim, I just don't have the power -- TYPE: PodBayDoorResponse\n",
      "\n",
      "You: what is your name\n",
      "Geek: Call me Geni -- TYPE: NameQuery\n",
      "\n",
      "You: nice name!\n",
      "Geek: Mary said I a question and I answer then I ask him a question and he answer. -- TYPE: Gossip\n",
      "\n",
      "You: gossip\n",
      "Geek: Peter said he seems to him that I can not be very sure on anything. -- TYPE: Gossip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Note: Enter 'quit' to break the loop.\")    \n",
    "while True:                                                 \n",
    "    query = input('You: ') \n",
    "    if query.lower() == 'quit': \n",
    "        break\n",
    "    bot_response, typ = response(query) \n",
    "    print('Geek: {} -- TYPE: {}'.format(bot_response, typ)) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef368d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
